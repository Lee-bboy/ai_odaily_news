#!/usr/bin/env python3
# -*- coding:utf-8 -*-
"""
æ™ºèƒ½æƒ…æ„Ÿæ ‡æ³¨è„šæœ¬
è‡ªåŠ¨æ ‡æ³¨ç°æœ‰æ•°æ®åº“ä¸­çš„æ–°é—»æ•°æ®æƒ…æ„Ÿ
"""

import pandas as pd
import numpy as np
import jieba
import re
import logging
from database import DatabaseManager
import configparser
from typing import Dict, List, Tuple
import time

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SentimentLabeler:
    """æ™ºèƒ½æƒ…æ„Ÿæ ‡æ³¨å™¨"""
    
    def __init__(self):
        # åŠ è½½æƒ…æ„Ÿè¯å…¸
        self.positive_words = self._load_positive_words()
        self.negative_words = self._load_negative_words()
        self.neutral_words = self._load_neutral_words()
        
        # é‡‘èç‰¹å®šè¯æ±‡
        self.financial_positive = self._load_financial_positive()
        self.financial_negative = self._load_financial_negative()
        
        # æƒ…æ„Ÿå¼ºåº¦è¯æ±‡
        self.intensity_words = self._load_intensity_words()
        
        # å¦å®šè¯
        self.negation_words = ['ä¸', 'æ²¡', 'æ— ', 'é', 'æœª', 'åˆ«', 'è«', 'å‹¿', 'æ¯‹', 'å¼—', 'å¦', 'å', 'é€†']
        
        # è½¬æŠ˜è¯
        self.turn_words = ['ä½†æ˜¯', 'ç„¶è€Œ', 'ä¸è¿‡', 'å¯æ˜¯', 'åªæ˜¯', 'å´', 'åè€Œ', 'åå€’', 'åè€Œ', 'åå€’']
        
    def _load_positive_words(self) -> set:
        """åŠ è½½æ­£é¢æƒ…æ„Ÿè¯æ±‡"""
        words = {
            'ä¸Šæ¶¨', 'ä¸Šå‡', 'èµ°é«˜', 'æ”€å‡', 'ä¸Šæ‰¬', 'å¢é•¿', 'å¢åŠ ', 'æé«˜', 'æå‡', 'æ”¹å–„',
            'åˆ©å¥½', 'å¥½æ¶ˆæ¯', 'ç§¯æ', 'æ­£é¢', 'ä¹è§‚', 'å¼ºåŠ²', 'ç¹è£', 'å…´æ—º', 'å‘è¾¾',
            'æˆåŠŸ', 'èƒœåˆ©', 'çªç ´', 'åˆ›æ–°', 'é¢†å…ˆ', 'ä¼˜ç§€', 'å“è¶Š', 'æ°å‡º', 'çªå‡º',
            'ç¨³å®š', 'å®‰å…¨', 'å¯é ', 'ä¿¡ä»»', 'ä¿¡å¿ƒ', 'å¸Œæœ›', 'æœºé‡', 'æœºä¼š', 'å‰æ™¯',
            'ç›ˆåˆ©', 'æ”¶ç›Š', 'å›æŠ¥', 'åˆ©æ¶¦', 'æ”¶å…¥', 'é”€å”®é¢', 'å¸‚åœºä»½é¢', 'ç«äº‰åŠ›'
        }
        return words
    
    def _load_negative_words(self) -> set:
        """åŠ è½½è´Ÿé¢æƒ…æ„Ÿè¯æ±‡"""
        words = {
            'ä¸‹è·Œ', 'ä¸‹é™', 'èµ°ä½', 'ä¸‹æŒ«', 'å›è½', 'å‡å°‘', 'é™ä½', 'æ¶åŒ–', 'è¡°é€€', 'èç¼©',
            'åˆ©ç©º', 'åæ¶ˆæ¯', 'æ¶ˆæ', 'è´Ÿé¢', 'æ‚²è§‚', 'ç–²è½¯', 'ä½è¿·', 'è§æ¡', 'å›°éš¾',
            'å¤±è´¥', 'æŸå¤±', 'äºæŸ', 'å€ºåŠ¡', 'é£é™©', 'å±æœº', 'é—®é¢˜', 'å›°éš¾', 'æŒ‘æˆ˜',
            'ä¸ç¨³å®š', 'ä¸å®‰å…¨', 'ä¸å¯é ', 'ä¸ä¿¡ä»»', 'å¤±æœ›', 'æ‹…å¿§', 'ææƒ§', 'ææ…Œ',
            'äºæŸ', 'æŸå¤±', 'å€ºåŠ¡', 'ç ´äº§', 'å€’é—­', 'è£å‘˜', 'å¤±ä¸š', 'ç»æµå±æœº'
        }
        return words
    
    def _load_neutral_words(self) -> set:
        """åŠ è½½ä¸­æ€§æƒ…æ„Ÿè¯æ±‡"""
        words = {
            'å¹³ç¨³', 'ç¨³å®š', 'ç»´æŒ', 'ä¿æŒ', 'è§‚å¯Ÿ', 'åˆ†æ', 'ç ”ç©¶', 'è°ƒæŸ¥', 'ç»Ÿè®¡',
            'å‘å¸ƒ', 'å…¬å¸ƒ', 'å®£å¸ƒ', 'é€šçŸ¥', 'æŠ¥å‘Š', 'æ•°æ®', 'æŒ‡æ ‡', 'è¶‹åŠ¿', 'å˜åŒ–',
            'æ”¿ç­–', 'è§„å®š', 'åˆ¶åº¦', 'æ ‡å‡†', 'è¦æ±‚', 'å»ºè®®', 'æ„è§', 'çœ‹æ³•', 'è§‚ç‚¹',
            'ä¼šè®®', 'è®¨è®º', 'åå•†', 'åˆä½œ', 'äº¤æµ', 'æ²Ÿé€š', 'è”ç³»', 'å…³ç³»', 'å½±å“'
        }
        return words
    
    def _load_financial_positive(self) -> set:
        """åŠ è½½é‡‘èæ­£é¢è¯æ±‡"""
        words = {
            'ç‰›å¸‚', 'æ¶¨åœ', 'å¤§æ¶¨', 'æš´æ¶¨', 'é£™å‡', 'çªç ´', 'æ–°é«˜', 'å†å²æ–°é«˜',
            'ä¸šç»©', 'ç›ˆåˆ©', 'å‡€åˆ©æ¶¦', 'è¥æ”¶', 'é”€å”®é¢', 'å¸‚åœºä»½é¢', 'è¡Œä¸šé¾™å¤´',
            'æ”¿ç­–æ”¯æŒ', 'å‡ç¨é™è´¹', 'é™æ¯', 'é™å‡†', 'æµåŠ¨æ€§', 'èµ„é‡‘é¢', 'æŠ•èµ„æœºä¼š',
            'å¹¶è´­', 'é‡ç»„', 'ä¸Šå¸‚', 'IPO', 'èèµ„', 'æŠ•èµ„', 'æ‰©å¼ ', 'å‘å±•'
        }
        return words
    
    def _load_financial_negative(self) -> set:
        """åŠ è½½é‡‘èè´Ÿé¢è¯æ±‡"""
        words = {
            'ç†Šå¸‚', 'è·Œåœ', 'å¤§è·Œ', 'æš´è·Œ', 'è·³æ°´', 'ç ´ä½', 'æ–°ä½', 'å†å²æ–°ä½',
            'ä¸šç»©ä¸‹æ»‘', 'äºæŸ', 'å‡€åˆ©æ¶¦ä¸‹é™', 'è¥æ”¶ä¸‹é™', 'é”€å”®é¢ä¸‹é™', 'å¸‚åœºä»½é¢ä¸‹é™',
            'æ”¿ç­–æ”¶ç´§', 'åŠ æ¯', 'åŠ å‡†', 'æµåŠ¨æ€§ç´§å¼ ', 'èµ„é‡‘é¢ç´§å¼ ', 'æŠ•èµ„é£é™©',
            'é€€å¸‚', 'ç ´äº§', 'å€ºåŠ¡è¿çº¦', 'ä¿¡ç”¨é£é™©', 'å¸‚åœºé£é™©', 'ç³»ç»Ÿæ€§é£é™©'
        }
        return words
    
    def _load_intensity_words(self) -> Dict[str, float]:
        """åŠ è½½æƒ…æ„Ÿå¼ºåº¦è¯æ±‡"""
        intensity = {
            # æå¼ºæ­£é¢
            'æš´æ¶¨': 2.0, 'é£™å‡': 2.0, 'çªç ´': 1.8, 'å†å²æ–°é«˜': 1.8, 'æ¶¨åœ': 1.8,
            'æå¤§åˆ©å¥½': 2.0, 'é‡å¤§çªç ´': 1.8, 'æ˜¾è‘—æ”¹å–„': 1.6, 'å¤§å¹…å¢é•¿': 1.6,
            
            # å¼ºæ­£é¢
            'å¤§æ¶¨': 1.5, 'ä¸Šæ¶¨': 1.2, 'å¢é•¿': 1.2, 'æ”¹å–„': 1.2, 'åˆ©å¥½': 1.3,
            'ç§¯æ': 1.2, 'ä¹è§‚': 1.2, 'å¼ºåŠ²': 1.3, 'ä¼˜ç§€': 1.2, 'æˆåŠŸ': 1.3,
            
            # ä¸­ç­‰æ­£é¢
            'å°å¹…ä¸Šæ¶¨': 0.8, 'å¾®æ¶¨': 0.6, 'ç¨³å®š': 0.5, 'ç»´æŒ': 0.5, 'å¹³ç¨³': 0.5,
            
            # æå¼ºè´Ÿé¢
            'æš´è·Œ': -2.0, 'è·³æ°´': -2.0, 'ç ´ä½': -1.8, 'å†å²æ–°ä½': -1.8, 'è·Œåœ': -1.8,
            'æå¤§åˆ©ç©º': -2.0, 'é‡å¤§å±æœº': -1.8, 'æ˜¾è‘—æ¶åŒ–': -1.6, 'å¤§å¹…ä¸‹é™': -1.6,
            
            # å¼ºè´Ÿé¢
            'å¤§è·Œ': -1.5, 'ä¸‹è·Œ': -1.2, 'ä¸‹é™': -1.2, 'æ¶åŒ–': -1.2, 'åˆ©ç©º': -1.3,
            'æ¶ˆæ': -1.2, 'æ‚²è§‚': -1.2, 'ç–²è½¯': -1.3, 'å¤±è´¥': -1.3, 'äºæŸ': -1.3,
            
            # ä¸­ç­‰è´Ÿé¢
            'å°å¹…ä¸‹è·Œ': -0.8, 'å¾®è·Œ': -0.6, 'è°ƒæ•´': -0.5, 'æ³¢åŠ¨': -0.3
        }
        return intensity
    
    def analyze_sentiment(self, title: str, description: str) -> Tuple[str, float]:
        """åˆ†ææ–‡æœ¬æƒ…æ„Ÿ"""
        if pd.isna(title):
            title = ""
        if pd.isna(description):
            description = ""
        
        # ç»„åˆæ ‡é¢˜å’Œæè¿°
        combined_text = f"{title} {description}".strip()
        if not combined_text:
            return 'neutral', 0.0
        
        # åˆ†è¯
        words = list(jieba.cut(combined_text))
        
        # è®¡ç®—æƒ…æ„Ÿåˆ†æ•°
        sentiment_score = 0.0
        word_count = len(words)
        
        # æ£€æŸ¥å¦å®šè¯å’Œè½¬æŠ˜è¯
        has_negation = any(word in combined_text for word in self.negation_words)
        has_turn = any(word in combined_text for word in self.turn_words)
        
        # åˆ†ææ¯ä¸ªè¯çš„æƒ…æ„Ÿ
        for word in words:
            word_score = 0.0
            
            # æ£€æŸ¥æƒ…æ„Ÿå¼ºåº¦è¯æ±‡
            if word in self.intensity_words:
                word_score = self.intensity_words[word]
            # æ£€æŸ¥æ­£é¢è¯æ±‡
            elif word in self.positive_words or word in self.financial_positive:
                word_score = 1.0
            # æ£€æŸ¥è´Ÿé¢è¯æ±‡
            elif word in self.negative_words or word in self.financial_negative:
                word_score = -1.0
            # æ£€æŸ¥ä¸­æ€§è¯æ±‡
            elif word in self.neutral_words:
                word_score = 0.0
            
            sentiment_score += word_score
        
        # å¤„ç†å¦å®šè¯
        if has_negation:
            sentiment_score = -sentiment_score * 0.8
        
        # å¤„ç†è½¬æŠ˜è¯
        if has_turn:
            sentiment_score = sentiment_score * 0.6
        
        # æ ‡å‡†åŒ–åˆ†æ•°
        if word_count > 0:
            normalized_score = sentiment_score / word_count
        else:
            normalized_score = 0.0
        
        # ç¡®å®šæƒ…æ„Ÿæ ‡ç­¾
        if normalized_score > 0.1:
            sentiment = 'positive'
        elif normalized_score < -0.1:
            sentiment = 'negative'
        else:
            sentiment = 'neutral'
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = min(abs(normalized_score) * 2, 0.95)
        confidence = max(confidence, 0.5)  # æœ€ä½ç½®ä¿¡åº¦0.5
        
        return sentiment, confidence
    
    def batch_analyze(self, data: List[Dict]) -> List[Dict]:
        """æ‰¹é‡åˆ†ææƒ…æ„Ÿ"""
        results = []
        
        for i, item in enumerate(data):
            title = item.get('title', '')
            description = item.get('description', '')
            
            sentiment, confidence = self.analyze_sentiment(title, description)
            
            result = item.copy()
            result['predicted_sentiment'] = sentiment
            result['confidence'] = confidence
            
            results.append(result)
            
            if (i + 1) % 100 == 0:
                logger.info(f"å·²å¤„ç† {i + 1}/{len(data)} æ¡æ•°æ®")
        
        return results

def auto_label_database_data():
    """è‡ªåŠ¨æ ‡æ³¨æ•°æ®åº“ä¸­çš„æ•°æ®"""
    
    try:
        logger.info("å¼€å§‹è‡ªåŠ¨æ ‡æ³¨æ•°æ®åº“æ•°æ®...")
        
        # è¿æ¥æ•°æ®åº“
        db_manager = DatabaseManager()
        
        # è·å–æœªæ ‡æ³¨çš„æ•°æ®
        logger.info("è·å–æœªæ ‡æ³¨æ•°æ®...")
        unlabeled_data = db_manager.get_unlabeled_data()
        
        if not unlabeled_data:
            logger.info("æ²¡æœ‰æ‰¾åˆ°æœªæ ‡æ³¨çš„æ•°æ®")
            return
        
        logger.info(f"æ‰¾åˆ° {len(unlabeled_data)} æ¡æœªæ ‡æ³¨æ•°æ®")
        
        # åˆ›å»ºæ ‡æ³¨å™¨
        labeler = SentimentLabeler()
        
        # æ‰¹é‡åˆ†ææƒ…æ„Ÿ
        logger.info("å¼€å§‹æƒ…æ„Ÿåˆ†æ...")
        labeled_results = labeler.batch_analyze(unlabeled_data)
        
        # ç»Ÿè®¡æ ‡æ³¨ç»“æœ
        sentiment_counts = {}
        for result in labeled_results:
            sentiment = result['predicted_sentiment']
            sentiment_counts[sentiment] = sentiment_counts.get(sentiment, 0) + 1
        
        logger.info("æ ‡æ³¨ç»“æœç»Ÿè®¡:")
        for sentiment, count in sentiment_counts.items():
            logger.info(f"  {sentiment}: {count}")
        
        # æ›´æ–°æ•°æ®åº“
        logger.info("å¼€å§‹æ›´æ–°æ•°æ®åº“...")
        
        updates = []
        for result in labeled_results:
            updates.append({
                'id': result['id'],
                'sentiment': result['predicted_sentiment'],
                'confidence': result['confidence']
            })
        
        # æ‰¹é‡æ›´æ–°
        db_manager.batch_update_sentiment(updates)
        
        logger.info(f"âœ… æˆåŠŸæ ‡æ³¨ {len(updates)} æ¡æ•°æ®")
        
        # éªŒè¯ç»“æœ
        labeled_data = db_manager.get_labeled_data()
        logger.info(f"æ•°æ®åº“ä¸­ç°æœ‰å·²æ ‡æ³¨æ•°æ®: {len(labeled_data)} æ¡")
        
        return True
        
    except Exception as e:
        logger.error(f"è‡ªåŠ¨æ ‡æ³¨å¤±è´¥: {e}")
        return False

def preview_labeling_results(limit: int = 10):
    """é¢„è§ˆæ ‡æ³¨ç»“æœ"""
    
    try:
        logger.info(f"é¢„è§ˆå‰ {limit} æ¡æ ‡æ³¨ç»“æœ...")
        
        # è¿æ¥æ•°æ®åº“
        db_manager = DatabaseManager()
        
        # è·å–å·²æ ‡æ³¨æ•°æ®
        labeled_data = db_manager.get_labeled_data()
        
        if not labeled_data:
            logger.info("æ²¡æœ‰æ‰¾åˆ°å·²æ ‡æ³¨æ•°æ®")
            return
        
        # æ˜¾ç¤ºå‰å‡ æ¡ç»“æœ
        for i, row in enumerate(labeled_data.head(limit).itertuples()):
            print(f"\n--- ç¬¬ {i+1} æ¡ ---")
            print(f"ID: {getattr(row, db_manager.id_column)}")
            print(f"æ ‡é¢˜: {getattr(row, db_manager.title_column)}")
            print(f"æè¿°: {getattr(row, db_manager.description_column)}")
            print(f"æƒ…æ„Ÿ: {getattr(row, db_manager.label_column)}")
            print(f"ç½®ä¿¡åº¦: {getattr(row, db_manager.confidence_column)}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        sentiment_counts = labeled_data[db_manager.label_column].value_counts()
        print(f"\næƒ…æ„Ÿåˆ†å¸ƒ:")
        for sentiment, count in sentiment_counts.items():
            print(f"  {sentiment}: {count}")
        
        avg_confidence = labeled_data[db_manager.confidence_column].mean()
        print(f"å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        
    except Exception as e:
        logger.error(f"é¢„è§ˆå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("è‚¡ç¥¨æ¶ˆæ¯æƒ…æ„Ÿåˆ†æç³»ç»Ÿ - æ™ºèƒ½æƒ…æ„Ÿæ ‡æ³¨")
    print("=" * 60)
    
    print("\né€‰æ‹©æ“ä½œ:")
    print("1. è‡ªåŠ¨æ ‡æ³¨æ•°æ®åº“ä¸­çš„æ‰€æœ‰æœªæ ‡æ³¨æ•°æ®")
    print("2. é¢„è§ˆå·²æ ‡æ³¨æ•°æ®çš„ç»“æœ")
    print("3. é€€å‡º")
    
    while True:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()
        
        if choice == '1':
            print("\nå¼€å§‹è‡ªåŠ¨æ ‡æ³¨...")
            success = auto_label_database_data()
            
            if success:
                print("\nğŸ‰ è‡ªåŠ¨æ ‡æ³¨å®Œæˆï¼")
                print("ç°åœ¨å¯ä»¥è¿è¡Œè®­ç»ƒè„šæœ¬:")
                print("python3 enhanced_train_model.py")
            else:
                print("\nâŒ è‡ªåŠ¨æ ‡æ³¨å¤±è´¥")
            break
            
        elif choice == '2':
            print("\né¢„è§ˆæ ‡æ³¨ç»“æœ...")
            preview_labeling_results()
            break
            
        elif choice == '3':
            print("é€€å‡ºç¨‹åº")
            break
            
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

if __name__ == "__main__":
    main()
