#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¹è¿›çš„è‚¡ç¥¨æ¶ˆæ¯æƒ…æ„Ÿåˆ†æç³»ç»Ÿæµ‹è¯•è„šæœ¬
åŒ…å«æ›´å¥½çš„æ•°æ®éªŒè¯å’Œé”™è¯¯å¤„ç†
"""

import sys
import os
import logging
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_imports():
    """æµ‹è¯•æ‰€æœ‰å¿…è¦çš„æ¨¡å—å¯¼å…¥"""
    print("=" * 50)
    print("æµ‹è¯•æ¨¡å—å¯¼å…¥...")
    
    try:
        import torch
        print(f"âœ“ PyTorch: {torch.__version__}")
    except ImportError as e:
        print(f"âœ— PyTorchå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import transformers
        print(f"âœ“ Transformers: {transformers.__version__}")
    except ImportError as e:
        print(f"âœ— Transformerså¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import pandas as pd
        print(f"âœ“ Pandas: {pd.__version__}")
    except ImportError as e:
        print(f"âœ— Pandaså¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import numpy as np
        print(f"âœ“ NumPy: {np.__version__}")
    except ImportError as e:
        print(f"âœ— NumPyå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import sklearn
        print(f"âœ“ Scikit-learn: {sklearn.__version__}")
    except ImportError as e:
        print(f"âœ— Scikit-learnå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import jieba
        print(f"âœ“ Jieba: {jieba.__version__}")
    except ImportError as e:
        print(f"âœ— Jiebaå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import pymysql
        print(f"âœ“ PyMySQL: {pymysql.__version__}")
    except ImportError as e:
        print(f"âœ— PyMySQLå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import sqlalchemy
        print(f"âœ“ SQLAlchemy: {sqlalchemy.__version__}")
    except ImportError as e:
        print(f"âœ— SQLAlchemyå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    print("âœ“ æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
    return True

def test_custom_modules():
    """æµ‹è¯•è‡ªå®šä¹‰æ¨¡å—"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•è‡ªå®šä¹‰æ¨¡å—...")
    
    try:
        from database import DatabaseManager
        print("âœ“ DatabaseManagerå¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âœ— DatabaseManagerå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from data_processor import TextProcessor, DatasetBuilder
        print("âœ“ TextProcessorå’ŒDatasetBuilderå¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âœ— TextProcessorå’ŒDatasetBuilderå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from model import SentimentClassifier
        print("âœ“ SentimentClassifierå¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âœ— SentimentClassifierå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from trainer import SentimentTrainer
        print("âœ“ SentimentTrainerå¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âœ— SentimentTrainerå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    print("âœ“ æ‰€æœ‰è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
    return True

def test_configuration():
    """æµ‹è¯•é…ç½®æ–‡ä»¶"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•é…ç½®æ–‡ä»¶...")
    
    try:
        import configparser
        config = configparser.ConfigParser()
        
        if not os.path.exists('config.ini'):
            print("âœ— é…ç½®æ–‡ä»¶config.iniä¸å­˜åœ¨")
            return False
        
        config.read('config.ini', encoding='utf-8')
        
        # æ£€æŸ¥å¿…è¦çš„é…ç½®èŠ‚
        required_sections = ['DATABASE', 'MODEL', 'DATA', 'FINETUNE']
        for section in required_sections:
            if section not in config:
                print(f"âœ— ç¼ºå°‘é…ç½®èŠ‚: {section}")
                return False
        
        print("âœ“ é…ç½®æ–‡ä»¶ç»“æ„æ­£ç¡®")
        
        # æ˜¾ç¤ºå…³é”®é…ç½®
        print("\næ•°æ®åº“é…ç½®:")
        print(f"  ä¸»æœº: {config.get('DATABASE', 'host', fallback='N/A')}")
        print(f"  æ•°æ®åº“: {config.get('DATABASE', 'database', fallback='N/A')}")
        
        print("\næ¨¡å‹é…ç½®:")
        print(f"  æ¨¡å‹åç§°: {config.get('MODEL', 'model_name', fallback='N/A')}")
        print(f"  æ‰¹æ¬¡å¤§å°: {config.get('MODEL', 'batch_size', fallback='N/A')}")
        
        print("\næ•°æ®é…ç½®:")
        print(f"  è¡¨å: {config.get('DATA', 'table_name', fallback='N/A')}")
        print(f"  æ ‡é¢˜åˆ—: {config.get('DATA', 'title_column', fallback='N/A')}")
        print(f"  æè¿°åˆ—: {config.get('DATA', 'description_column', fallback='N/A')}")
        
        return True
        
    except Exception as e:
        print(f"âœ— é…ç½®æ–‡ä»¶æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_text_processing():
    """æµ‹è¯•æ–‡æœ¬å¤„ç†åŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•æ–‡æœ¬å¤„ç†åŠŸèƒ½...")
    
    try:
        from data_processor import TextProcessor
        
        processor = TextProcessor()
        
        # æµ‹è¯•æ–‡æœ¬æ¸…ç†
        test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼åŒ…å«æ ‡ç‚¹ç¬¦å·å’Œç©ºæ ¼   "
        cleaned = processor.clean_text(test_text)
        print(f"åŸæ–‡: '{test_text}'")
        print(f"æ¸…ç†å: '{cleaned}'")
        
        # æµ‹è¯•æ ‡é¢˜å’Œæè¿°ç»„åˆ
        title = "è‚¡ç¥¨å¤§æ¶¨"
        description = "ä»Šæ—¥è‚¡å¸‚è¡¨ç°å¼ºåŠ²ï¼Œä¸»è¦æŒ‡æ•°ä¸Šæ¶¨è¶…è¿‡2%"
        combined = processor.combine_title_description(title, description)
        print(f"æ ‡é¢˜: '{title}'")
        print(f"æè¿°: '{description}'")
        print(f"ç»„åˆå: '{combined}'")
        
        print("âœ“ æ–‡æœ¬å¤„ç†åŠŸèƒ½æ­£å¸¸")
        return True
        
    except Exception as e:
        print(f"âœ— æ–‡æœ¬å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_data_analysis():
    """æµ‹è¯•æ•°æ®åˆ†æåŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•æ•°æ®åˆ†æåŠŸèƒ½...")
    
    try:
        import pandas as pd
        from data_processor import TextProcessor, DatasetBuilder
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'title': ['è‚¡ç¥¨å¤§æ¶¨', 'å¸‚åœºä¸‹è·Œ', 'æ”¿ç­–åˆ©å¥½', 'ç»æµæ•°æ®', 'å¤®è¡Œé™æ¯'],
            'description': [
                'ä»Šæ—¥è‚¡å¸‚è¡¨ç°å¼ºåŠ²ï¼Œä¸»è¦æŒ‡æ•°ä¸Šæ¶¨è¶…è¿‡2%',
                'å—å¤–éƒ¨å› ç´ å½±å“ï¼Œå¸‚åœºå‡ºç°è°ƒæ•´',
                'æ”¿åºœå‡ºå°æ–°æ”¿ç­–ï¼Œæ”¯æŒç»æµå‘å±•',
                'æœ€æ–°ç»æµæ•°æ®æ˜¾ç¤ºå¢é•¿æ€åŠ¿è‰¯å¥½',
                'å¤®è¡Œå®£å¸ƒé™æ¯ï¼Œé‡Šæ”¾æµåŠ¨æ€§'
            ],
            'sentiment': ['positive', 'negative', 'positive', 'positive', 'positive']
        })
        
        print(f"æµ‹è¯•æ•°æ®è¡Œæ•°: {len(test_data)}")
        print("æµ‹è¯•æ•°æ®:")
        for _, row in test_data.iterrows():
            print(f"  æ ‡é¢˜: {row['title']}")
            print(f"  æè¿°: {row['description']}")
            print(f"  æƒ…æ„Ÿ: {row['sentiment']}")
            print()
        
        # æµ‹è¯•æ•°æ®å¤„ç†
        processor = TextProcessor()
        builder = DatasetBuilder(processor)
        
        texts, labels = builder.prepare_dataset(
            test_data, 'title', 'description', 'sentiment'
        )
        
        print(f"å¤„ç†åçš„æ–‡æœ¬æ•°é‡: {len(texts)}")
        print(f"æ ‡ç­¾æ•°é‡: {len(labels)}")
        
        if len(texts) > 0:
            # æµ‹è¯•æ•°æ®é›†åˆ†å‰²
            try:
                train_data, val_data, test_data = builder.split_dataset(texts, labels)
                print("âœ“ æ•°æ®é›†åˆ†å‰²æˆåŠŸ")
                print(f"  è®­ç»ƒé›†: {len(train_data[0])} æ ·æœ¬")
                print(f"  éªŒè¯é›†: {len(val_data[0])} æ ·æœ¬")
                print(f"  æµ‹è¯•é›†: {len(test_data[0])} æ ·æœ¬")
            except Exception as e:
                print(f"âš ï¸  æ•°æ®é›†åˆ†å‰²å¤±è´¥: {e}")
                print("  è¿™å¯èƒ½æ˜¯ç”±äºæ ·æœ¬æ•°é‡ä¸è¶³å¯¼è‡´çš„ï¼Œåœ¨çœŸå®ç¯å¢ƒä¸­åº”è¯¥ä¸æ˜¯é—®é¢˜")
        
        return True
        
    except Exception as e:
        print(f"âœ— æ•°æ®åˆ†ææµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    
    try:
        from model import SentimentClassifier
        from transformers import AutoTokenizer
        
        # ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•
        model_name = "hfl/chinese-bert-wwm-ext"
        
        print(f"åŠ è½½tokenizer: {model_name}")
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        print("âœ“ TokenizeråŠ è½½æˆåŠŸ")
        
        print("åˆ›å»ºæ¨¡å‹...")
        model = SentimentClassifier(model_name, num_labels=3)
        print("âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ¨¡å‹å‚æ•°
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"æ¨¡å‹æ€»å‚æ•°: {total_params:,}")
        print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        
        return True
        
    except Exception as e:
        print(f"âœ— æ¨¡å‹åˆ›å»ºæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("è‚¡ç¥¨æ¶ˆæ¯æƒ…æ„Ÿåˆ†æç³»ç»Ÿ - æ”¹è¿›æµ‹è¯•è„šæœ¬")
    print("=" * 60)
    
    tests = [
        ("æ¨¡å—å¯¼å…¥", test_imports),
        ("è‡ªå®šä¹‰æ¨¡å—", test_custom_modules),
        ("é…ç½®æ–‡ä»¶", test_configuration),
        ("æ–‡æœ¬å¤„ç†", test_text_processing),
        ("æ•°æ®åˆ†æ", test_data_analysis),
        ("æ¨¡å‹åˆ›å»º", test_model_creation)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        try:
            if test_func():
                passed += 1
                print(f"âœ“ {test_name} æµ‹è¯•é€šè¿‡")
            else:
                print(f"âœ— {test_name} æµ‹è¯•å¤±è´¥")
        except Exception as e:
            print(f"âœ— {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
        
        print()
    
    print("=" * 60)
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå¯ä»¥æ­£å¸¸è¿è¡Œ")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³é…ç½®")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
